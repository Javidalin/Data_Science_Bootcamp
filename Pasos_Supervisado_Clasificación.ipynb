{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendizaje Supervisado, Problema de Clasificación (binario o multiclase):\n",
    "\n",
    "1. Entendimiento del problema (selección de la métrica más adecuada: Accuracy, Precision, Recall)\n",
    "2. Obtención de datos y primer contacto  \n",
    "3. Train y Test  <- PARTIMOS DE AQUI  \n",
    "4. MiniEDA: \n",
    "    - Análisis del target (binario o multiclase): Desbalanceado o no (o mucho o poco)\n",
    "    - Análisis bivariante:\n",
    "        Categórica-categórica (distrubución frecuencias, discrimina o no)\n",
    "        Numérica-categórica (distribución histogramas, discrimina o no)\n",
    "    - Entendimiento de las features, selección de las mismas (si es necesario, podemos hacer primer nivel, segundo nivel...)\n",
    "5. Preparación del dataset de Train, en función del modelo (sí es sensible a la escala o no):\n",
    "    - No es sensible a la escala (árboles, ensembles):\n",
    "        - Si todo está en variables numéricas, ya no hay que hacer nada más\n",
    "        - Si hay que hacer conversión de categóricas -> se convierten\n",
    "    - Si es sensible a la escala (knn, logistic regressor):\n",
    "        - Conversión de categóricas:\n",
    "            - Binarias -> 0-1\n",
    "            - Ordinales -> Ordinal Encoder o mapeo (\"enero\":1 , \"febrero\":2 , \"marzo\":3,...)\n",
    "            - No ordinales -> OneHot Enconding (pd.get_dummies u OneHotEncoder Scikit-learn) u ordinal free style\n",
    "        - Tratamiento de numéricas:\n",
    "            - Empujoncito a las que se puedan beneficiar (distribución log normal, alta concentración en valores bajos y rangos muy altos) -> Transformación con log10, o sqrt, o cbrt, etc.\n",
    "            - Después de transformar -> Escalar:\n",
    "                - Normalización MinMax [0,1] o [-1,1]\n",
    "                - Estandarización StandardScaler -> todo centrado entorno a standard dev \n",
    "    - MUY IMPORTANTE: TODO LO APLICADO A TRAIN SE APLICA A TEST !!!!!!!!\n",
    "6. Selección e instanciación de modelos. Baseline.\n",
    "7. Comparación de modelos (normalmente sin optimizar por eficiencia):\n",
    "    - Validación cruzada y en base a la métrica de negocio (accuracy, precision, recall -> \"balanced_accuracy\")\n",
    "    - Nota: lo haremos por comparación con validación, puedes hacerlo por comparación de modelos de hiperparámetros optimizados, si así lo prefieres)  TIEMPO es la clave -> 1) Tuneo/Ajusto los hiperparámetros; 2) validación cruzada (set de validación)\n",
    "8. Selección de modelo -> Optimización de hiperparámetros (ten en cuenta la nota de 7) con GridSearchCV o RandomizedSearchCV\n",
    "9. Si el modelo es terrible por culpa de los datos:\n",
    "    - Equilibrado del train set (Oversampling SMOTE, Undersampling con resample o con RandomUnderSampler)\n",
    "    - Sin equilibrado pero con el Hiperparámetro de \"class_weight\"\n",
    "10. Evaluación de métricas finales tras el tuneo o el equilibrado.\n",
    "10. Evaluación contra test.  \n",
    "11. Análisis de errores, posibles acciones futuras.  \n",
    "12. EXTRA: Persistencia del modelo en disco.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
